# -*- coding: utf-8 -*-
"""autotrans.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J0lOG1VIwvWklBk6ojE7F7aKEZVbLjMl
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue May 30 14:04:24 2023

@author: subhadramokashe
"""

import numpy as np

from tqdm import tqdm, trange
import pickle

import torch
import torch.nn as nn
from torch.optim import Adam
from torch.nn import CrossEntropyLoss
from torch.utils.data import DataLoader
from torch.utils.data import TensorDataset, DataLoader
from torchvision.transforms import ToTensor
from torchvision.datasets.mnist import MNIST
import matplotlib.pyplot as plt

np.random.seed(0)
torch.manual_seed(0)
device = torch.device("cuda") if torch.cuda.is_available() else print("why?")
print(f'Selected device: {device}')

def patchify(images, n_patches):
    images = images.to(device)
    n, c, h, w = images.shape

    assert h == w, "Patchify method is implemented for square images only"

    patches = torch.zeros(n, n_patches ** 2, h * w * c // n_patches ** 2)
    patch_size = h // n_patches


    for idx, image in enumerate(images):
        #print(idx)
        for i in range(n_patches):
            for j in range(n_patches):
                patch = image[:, i * patch_size: (i + 1) * patch_size, j * patch_size: (j + 1) * patch_size]
                patches[idx, i * n_patches + j] = patch.flatten()
                #print(patches.shape)
    return patches

def depatchify(patches, n_patches):
    n, np2, sp2 = patches.shape
    #print(patches.shape)
    h = w = int(np.sqrt(np2)*np.sqrt(sp2))
    c = int(np2/(n_patches*n_patches))
    iimages =torch.zeros(n, c, h, w)
    patch_size = int(np.sqrt(sp2))
    for idx, patches in enumerate(patches):
        for i in range(n_patches):
            for j in range(n_patches):
                    #print(patches[i])
                    ipatch = torch.reshape(patches[i * n_patches + j], [1,c,patch_size,patch_size])
                    iimages[idx,:,i * patch_size: (i + 1) * patch_size, j * patch_size: (j + 1) * patch_size] = ipatch
    return iimages


def get_positional_embeddings(sequence_length, d):
    result = torch.ones(sequence_length, d)
    for i in range(sequence_length):
        for j in range(d):
            result[i][j] = np.sin(i / (10000 ** (j / d))) if j % 2 == 0 else np.cos(i / (10000 ** ((j - 1) / d)))

    return result


class MyViT(nn.Module):
  def __init__(self, chw=(1, 28, 28), n_patches=7, n_blocks=2, hidden_d=10, n_heads=2,out_d = 1):
    # Super constructor
    super(MyViT, self).__init__()

    # Attributes
    self.chw = chw # (C, H, W)
    self.n_patches = n_patches
    self.hidden_d = hidden_d

    assert chw[1] % n_patches == 0, "Input shape not entirely divisible by number of patches"
    assert chw[2] % n_patches == 0, "Input shape not entirely divisible by number of patches"
    self.patch_size = (chw[1] / n_patches, chw[2] / n_patches)

    # 1) Linear mapper
    self.input_d = int(chw[0] * self.patch_size[0] * self.patch_size[1])
    self.linear_mapper = nn.Linear(self.input_d, self.hidden_d)
    self.linear_mapper = self.linear_mapper.to(device)
    self.linear_mapper2 = nn.Linear( self.hidden_d,self.input_d)

    # 2) Learnable classifiation token
    self.class_token = nn.Parameter(torch.rand(1, self.hidden_d))

    # 3) Positional embedding
    self.register_buffer('positional_embeddings', get_positional_embeddings(n_patches ** 2 + 1, hidden_d), persistent=False)

    # 4) Transformer encoder blocks
    self.blocks = nn.ModuleList([MyViTBlock(hidden_d, n_heads) for _ in range(n_blocks)])

    self.iblocks = nn.ModuleList([MyViTBlock(hidden_d, n_heads) for _ in range(n_blocks)])

    # 5) encoder to latent to deocder
    self.mlp1 = nn.Sequential(nn.Linear(self.hidden_d, 1),nn.GELU())
    
    #self.mlp2 = nn.Sequential(nn.Linear(n_patches*n_patches,out_d),nn.GELU())
    
    #self.mlp3 = nn.Sequential(nn.Linear(out_d,n_patches*n_patches),nn.GELU())
    
    self.mlp4 = nn.Sequential(nn.Linear(1,self.hidden_d),nn.GELU())
    self.mlpl = nn.Sequential(nn.Linear(self.hidden_d, out_d),nn.GELU())
    self.mlpl1 = nn.Linear(out_d,self.hidden_d )
    self.rnn1 = nn.RNN(input_size= self.hidden_d, hidden_size= self.hidden_d*4, num_layers = 1,batch_first = True)
    self.clsf = nn.Linear(self.hidden_d*4, self.hidden_d )
    
    
    #self.mlp = nn.Sequential(nn.Linear(self.hidden_d, out_d),nn.GELU(), nn.Linear(out_d,self.hidden_d ))

    # 6) Positional embedding
    self.register_buffer('ipositional_embeddings', get_positional_embeddings(n_patches ** 2, hidden_d), persistent=False)







  def forward(self, images):

      n, c, h, w = images.shape
      patches = patchify(images, self.n_patches).to(device)

      tokens = self.linear_mapper(patches).to(device)
      tokens = torch.cat((self.class_token.expand(n, 1, -1), tokens), dim=1)
      out = tokens + self.positional_embeddings.repeat(n, 1, 1)
      for block in self.blocks:
          out = block(out)
          #print(out[:,0].shape)

      #print(out.shape)
      lat = self.mlpl(out[:,1:,:])




      return lat, y_pred


class MyMSA(nn.Module):
    def __init__(self, d, n_heads=2):
        super(MyMSA, self).__init__()
        self.d = d
        self.n_heads = n_heads

        assert d % n_heads == 0, f"Can't divide dimension {d} into {n_heads} heads"

        d_head = int(d / n_heads)
        self.q_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])
        self.k_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])
        self.v_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])
        self.d_head = d_head
        self.softmax = nn.Softmax(dim=-1)

    def forward(self, sequences):
        # Sequences has shape (N, seq_length, token_dim)
        # We go into shape    (N, seq_length, n_heads, token_dim / n_heads)
        # And come back to    (N, seq_length, item_dim)  (through concatenation)
        result = []
        for sequence in sequences:
            seq_result = []
            for head in range(self.n_heads):
                q_mapping = self.q_mappings[head]
                k_mapping = self.k_mappings[head]
                v_mapping = self.v_mappings[head]

                seq = sequence[:, head * self.d_head: (head + 1) * self.d_head]
                q, k, v = q_mapping(seq), k_mapping(seq), v_mapping(seq)

                attention = self.softmax(q @ k.T / (self.d_head ** 0.5))
                seq_result.append(attention @ v)
            result.append(torch.hstack(seq_result))
        return torch.cat([torch.unsqueeze(r, dim=0) for r in result])





class MyViTBlock(nn.Module):
    def __init__(self, hidden_d, n_heads, mlp_ratio=4):
        super(MyViTBlock, self).__init__()
        self.hidden_d = hidden_d
        self.n_heads = n_heads

        self.norm1 = nn.LayerNorm(hidden_d)
        self.mhsa = MyMSA(hidden_d, n_heads)
        self.mlp = nn.Sequential(nn.Linear(hidden_d, mlp_ratio * hidden_d),nn.GELU(),nn.Linear(mlp_ratio * hidden_d, hidden_d))
        self.norm2 = nn.LayerNorm(hidden_d)


    def forward(self, x):
        out = x + self.mhsa(self.norm1(x))
        out = out + self.mlp(self.norm2(out))
        return out
    
def main():

    with open('train_double_data.pkl','rb') as f: traindata = pickle.load(f)
    with open('train_double_labels.pkl','rb') as f: trainlabels = pickle.load(f)
    
    with open('test_double_data.pkl','rb') as f: testdata = pickle.load(f)
    with open('test_double_labels.pkl','rb') as f: testlabels = pickle.load(f)
    
    traindata = traindata.reshape(25000,2,1,28,28)
    testdata = testdata.reshape(5000,2,1,28,28)
   
    
    traintensorx = torch.Tensor(traindata)
    print(traintensorx.shape) # transform to torch tensor
    traintensory = torch.Tensor(trainlabels)
    print(traintensory.shape)

    train_set = TensorDataset(traintensorx, traintensory)
    testtensorx = torch.Tensor(testdata)
    testtensory = torch.Tensor(testlabels)
    test_set = TensorDataset(testtensorx, testtensory)

    train_loaderv = DataLoader(train_set, shuffle=True, batch_size=50)
    #test_loaderv = DataLoader(test_set, shuffle=False, batch_size=1)
    
    

    # Defining model and training options
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("Using device: ", device, f"({torch.cuda.get_device_name(device)})" if torch.cuda.is_available() else "")
    model = MyViT((1, 28, 28), n_patches=7, n_blocks=2, hidden_d=10, n_heads=2, out_d=100).to(device)
    N_EPOCHS = 100
    LR = 0.005

    # Training loop
    optimizer = Adam(model.parameters(), lr=LR)#, betas =(0.09,0.0999))
    criterion = torch.nn.MSELoss().to(device)
    #criterion2 = torch.nn.MSELoss().to(device)
    #optimizer2 = Adam(model.parameters(), lr=LR)
    for epoch in trange(N_EPOCHS, desc="Training"):
        train_loss = 0.0
        for batch in tqdm(train_loaderv, desc=f"Epoch {epoch + 1} in training", leave=False):
            x, y = batch
            
            #print(x.shape)
            x1 = x[:,0,:,:,:]
            #x2 = x[:,1,:,:,:]
            #x[0,1,:,:] = x2
            lat, x_hat1 = model(x1)
            #print(lat.shape)
            #x_hat = torch.stack((x_hat1, x_hat2), axis=1)
            #x_hat[0,0,:,:] = x_hat1
            #x_hat[0,1,:,:] = x_hat2
            #print(lat.shape)
            loss = criterion(x_hat1, x1).to(device)

            train_loss += loss.detach().cpu().item() / len(train_loaderv)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
        print(f"Epoch {epoch + 1}/{N_EPOCHS} loss: {train_loss:.8f}")


    #Test loop
    latent_save = np.zeros((10,49,100,500))
    with torch.no_grad():
        test_loss = 0.0
        for i in range(0,10):
            idx = testlabels == i
            test_set0= test_set[idx]
            #test_set0.data = test_set.data[idx]
            #print(test_set0.shape)
            test_loader = DataLoader(test_set0[0], shuffle=False)
            j = 0
            for batch in tqdm(test_loader, desc="Testing"):
                x= batch
                x= x.to(device)
                x1 = x[:,0,:,:,:]
                #x2 = x[:,1,:,:,:]
                lat, x_hat1 = model(x1)
                #x_hat = torch.stack((x_hat1, x_hat2), axis=1)
                
                loss = criterion(x_hat1, x1).to(device)


                #plt.s
                test_loss += loss.detach().cpu().item() / len(test_loader)
                
                latent_save[i,:,:,j] = np.squeeze(lat.numpy())
                if j < 499:
                    
                    j = j +1
                

        #plt.imshow(np.mean(latent_save,2))
        #plt.show()

        with open('ls_vis100ep.pkl','wb') as f: pickle.dump(latent_save, f)




            #correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()
            #total += len(x)
        print(f"Test loss: {test_loss:.8f}")
        #print(f"Test accuracy: {correct / total * 100:.2f}%")

def main1():
    # Loading data
    transform = ToTensor()

    train_set = MNIST(root='./../datasets', train=True, download=True, transform=transform)
    test_set = MNIST(root='./../datasets', train=False, download=True, transform=transform)
    test_set0 = MNIST(root='./../datasets', train=False, download=True, transform=transform)
    
    #idx = test_set.targets==0
    #print(idx)
    #test_set0.target = test_set0.targets[idx]
    #test_set0.data = test_set0.data[idx]

    train_loader = DataLoader(train_set, shuffle=True, batch_size=50)
    test_loader = DataLoader(test_set0, shuffle=False, batch_size=1)

    # Defining model and training options
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("Using device: ", device, f"({torch.cuda.get_device_name(device)})" if torch.cuda.is_available() else "")
    model = MyViT((1, 28, 28), n_patches=7, n_blocks=2, hidden_d=8, n_heads=2, out_d=10).to(device)
    N_EPOCHS = 1
    LR = 0.005

    # Training loop
    optimizer = Adam(model.parameters(), lr=LR)
    criterion = torch.nn.MSELoss().to(device)
    for epoch in trange(N_EPOCHS, desc="Training"):
        train_loss = 0.0
        for batch in tqdm(train_loader, desc=f"Epoch {epoch + 1} in training", leave=False):
            x, y = batch
            x, y = x.to(device), y.to(device)
            lat, x_hat = model(x)
            #print(lat.shape)
            loss = criterion(x_hat, x).to(device)

            train_loss += loss.detach().cpu().item() / len(train_loader)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        print(f"Epoch {epoch + 1}/{N_EPOCHS} loss: {train_loss:.4f}")

    # Test loop
    latent_save = np.zeros((10,49,100,500))
    with torch.no_grad():
        test_loss = 0.0
        for i in range(0,10):
            idx = test_set.targets == i
            test_set0.targets = test_set.targets[idx]
            test_set0.data = test_set.data[idx]
            #print(test_set0.shape)
            test_loader = DataLoader(test_set0, shuffle=False)
            j = 0
            for batch in tqdm(test_loader, desc="Testing"):
                x, y = batch
                x, y = x.to(device), y.to(device)
                latents, x_hat = model(x)
                
                loss = criterion(x_hat, x).to(device)
                #plt.show()
                test_loss += loss.detach().cpu().item() / len(test_loader)
                
                latent_save[i,:,:,j] = np.squeeze(latents.numpy())
                if j < 499:
                    
                    j = j +1
                

        #plt.imshow(np.mean(latent_save,2))
        #plt.show()

        plt.imshow(x[0,0,:,:])
        plt.show()
        plt.imshow(x_hat[0,0,:,:])
        plt.show()
        
        with open('ls_viss.pkl','wb') as f: pickle.dump(latent_save, f)




            #correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()
            #total += len(x)
        print(f"Test loss: {test_loss:.2f}")
        #print(f"Test accuracy: {correct / total * 100:.2f}%")


if __name__ == '__main__':
    main()